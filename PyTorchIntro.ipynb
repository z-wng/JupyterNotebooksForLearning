{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "\r\n",
    "from torchvision import datasets\r\n",
    "from torchvision.transforms import ToTensor, Lambda\r\n",
    "\r\n",
    "ds = datasets.FashionMNIST(\r\n",
    "    root=\"data\",\r\n",
    "    train=True,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor(),\r\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "26422272it [00:04, 6599492.94it/s]                              \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "29696it [00:00, 995285.84it/s]           \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4422656it [00:00, 6084225.44it/s]                             \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "6144it [00:00, ?it/s]                   "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "C:\\Users\\Zhe\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "ds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()\n",
       "Target transform: Lambda()"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unit 5: Building the model layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision import datasets, transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "print(f'Using {device} device')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a neural network\r\n",
    "\r\n",
    "The base class for all neural network modules in PyTorch is `torch.nn.Module`. More generally, the [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace provides all the building blocks for a neural net."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class NeuralNetwork(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(NeuralNetwork, self).__init__()\r\n",
    "        self.flatten = nn.Flatten()\r\n",
    "        self.linear_relu_stack = nn.Sequential(\r\n",
    "            nn.Linear(28 * 28, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 10),\r\n",
    "            nn.ReLU()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.flatten(x)\r\n",
    "        logits = self.linear_relu_stack(x)\r\n",
    "        return logits\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NB**: `forward()` shouldn't be called directly"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = NeuralNetwork().to(device)\r\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\r\n",
    "logits = model(X)\r\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\r\n",
    "y_pred = pred_prob.argmax(1)\r\n",
    "print(f'Predicted class: {y_pred}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted class: tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model breakdown"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "input_image = torch.rand(3, 28, 28)\r\n",
    "print(input_image.size())\r\n",
    "input_image"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[2.1058e-01, 5.9001e-01, 3.1618e-01,  ..., 3.9524e-01,\n",
       "          3.2162e-01, 3.6114e-01],\n",
       "         [6.4634e-01, 4.4112e-01, 4.0760e-01,  ..., 5.8843e-01,\n",
       "          1.0455e-01, 6.7277e-01],\n",
       "         [8.5326e-01, 4.0920e-01, 5.4896e-01,  ..., 5.9516e-01,\n",
       "          7.5553e-01, 8.3157e-01],\n",
       "         ...,\n",
       "         [2.5806e-01, 1.4574e-01, 7.6796e-01,  ..., 1.3272e-01,\n",
       "          2.4663e-01, 2.7345e-01],\n",
       "         [1.3655e-01, 3.4637e-01, 5.1549e-01,  ..., 8.7665e-01,\n",
       "          8.6684e-01, 8.5020e-01],\n",
       "         [3.3296e-01, 5.0664e-01, 7.7467e-01,  ..., 4.8543e-01,\n",
       "          6.2337e-01, 8.1998e-01]],\n",
       "\n",
       "        [[1.9082e-01, 2.1380e-01, 5.7392e-01,  ..., 6.4819e-02,\n",
       "          6.2593e-03, 1.0868e-01],\n",
       "         [1.5603e-01, 8.4725e-01, 3.9217e-01,  ..., 5.9693e-01,\n",
       "          7.4372e-01, 6.2483e-01],\n",
       "         [7.6496e-01, 6.9977e-01, 5.0129e-01,  ..., 3.3123e-01,\n",
       "          3.0496e-01, 9.9120e-03],\n",
       "         ...,\n",
       "         [4.6764e-01, 9.5213e-01, 2.9876e-01,  ..., 6.9338e-01,\n",
       "          8.2707e-01, 2.6219e-01],\n",
       "         [3.8697e-01, 8.4139e-01, 3.0091e-01,  ..., 5.7034e-01,\n",
       "          5.5294e-01, 3.1554e-01],\n",
       "         [4.8473e-01, 3.7603e-02, 6.1402e-01,  ..., 5.5899e-01,\n",
       "          8.3010e-01, 3.8216e-01]],\n",
       "\n",
       "        [[5.4110e-01, 6.8775e-01, 7.1002e-01,  ..., 3.3747e-01,\n",
       "          2.5142e-01, 7.7268e-01],\n",
       "         [1.3068e-01, 8.5425e-01, 4.0931e-01,  ..., 4.6521e-01,\n",
       "          1.8287e-01, 5.3121e-01],\n",
       "         [7.7634e-01, 4.9879e-01, 9.7721e-01,  ..., 5.8167e-01,\n",
       "          6.8700e-01, 7.6532e-02],\n",
       "         ...,\n",
       "         [2.0442e-01, 4.7380e-01, 5.1601e-01,  ..., 9.0824e-01,\n",
       "          5.7250e-01, 9.8389e-04],\n",
       "         [7.0411e-01, 4.8055e-01, 9.0262e-03,  ..., 8.7759e-01,\n",
       "          5.9765e-01, 3.8894e-02],\n",
       "         [3.8669e-01, 3.2488e-01, 4.1012e-01,  ..., 7.5061e-01,\n",
       "          9.9838e-01, 8.3456e-01]]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "flatten = nn.Flatten()\r\n",
    "flat_image = flatten(input_image)  # 28x28 image -> array of pixel values\r\n",
    "print(flat_image.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)  # linear transformation on the input using stored weights and biases\r\n",
    "hidden1 = layer1(flat_image)\r\n",
    "print(hidden1.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(f'Before ReLU: {hidden1}\\n=======================\\n')\r\n",
    "hidden1 = nn.ReLU()(hidden1)\r\n",
    "print(f'After ReLU: {hidden1}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before ReLU: tensor([[ 0.0696, -0.4402,  0.1617, -0.0284,  0.5393,  0.1870,  0.3323,  0.0616,\n",
      "         -0.5229, -0.0705,  0.0662, -0.3027,  0.4374,  0.1862, -0.3497,  0.1750,\n",
      "          0.0488,  0.1443,  0.0456,  0.2527],\n",
      "        [ 0.3013, -0.1426,  0.2289, -0.1085, -0.0030,  0.1591,  0.3011,  0.0328,\n",
      "         -0.2768, -0.0633,  0.1825,  0.1095,  0.6924, -0.5917, -0.4833,  0.2557,\n",
      "         -0.2206,  0.0251,  0.0274, -0.1531],\n",
      "        [ 0.1122, -0.1027,  0.7141, -0.0857,  0.8524,  0.2045,  0.4231, -0.3580,\n",
      "         -0.1873,  0.0025, -0.1181, -0.0369,  0.6290, -0.2200, -0.0826,  0.2365,\n",
      "         -0.0490,  0.3936, -0.2644,  0.2209]], grad_fn=<AddmmBackward>)\n",
      "=======================\n",
      "\n",
      "After ReLU: tensor([[0.0696, 0.0000, 0.1617, 0.0000, 0.5393, 0.1870, 0.3323, 0.0616, 0.0000,\n",
      "         0.0000, 0.0662, 0.0000, 0.4374, 0.1862, 0.0000, 0.1750, 0.0488, 0.1443,\n",
      "         0.0456, 0.2527],\n",
      "        [0.3013, 0.0000, 0.2289, 0.0000, 0.0000, 0.1591, 0.3011, 0.0328, 0.0000,\n",
      "         0.0000, 0.1825, 0.1095, 0.6924, 0.0000, 0.0000, 0.2557, 0.0000, 0.0251,\n",
      "         0.0274, 0.0000],\n",
      "        [0.1122, 0.0000, 0.7141, 0.0000, 0.8524, 0.2045, 0.4231, 0.0000, 0.0000,\n",
      "         0.0025, 0.0000, 0.0000, 0.6290, 0.0000, 0.0000, 0.2365, 0.0000, 0.3936,\n",
      "         0.0000, 0.2209]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\r\n",
    "\r\n",
    "An _ordered container_ of moduels. Data is passed through the modules in the order _as defined_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "seq_modules = nn.Sequential(\r\n",
    "    flatten,\r\n",
    "    layer1,\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Linear(20, 10)\r\n",
    ")\r\n",
    "logits = seq_modules(input_image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### nn.Softmax\r\n",
    "\r\n",
    "Parameter `dim` indicates the dimension along which softmax is applied."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "softmax = nn.Softmax(dim=1)\r\n",
    "pred_prob = softmax(logits)\r\n",
    "pred_prob"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0835, 0.0947, 0.1264, 0.1082, 0.0939, 0.1037, 0.1090, 0.1058, 0.1116,\n",
       "         0.0632],\n",
       "        [0.0751, 0.1009, 0.1076, 0.1178, 0.0951, 0.1005, 0.1226, 0.0978, 0.1098,\n",
       "         0.0727],\n",
       "        [0.0798, 0.1112, 0.1283, 0.1072, 0.0914, 0.0987, 0.1294, 0.1001, 0.0956,\n",
       "         0.0583]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "pred_prob.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model parameters\r\n",
    "\r\n",
    "All parameters (weights and biases) of a subclass of `nn.Module` are tracked in the model object and can be accessed with `parameters()` or `named_parameters()`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "for name, param in model.named_parameters():\r\n",
    "    print(f'Layer: {name}\\nSize: {param.size()}\\nValues:\\n{param[:2]}\\n==============\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Layer: linear_relu_stack.0.weight\n",
      "Size: torch.Size([512, 784])\n",
      "Values:\n",
      "tensor([[ 0.0166, -0.0087,  0.0113,  ...,  0.0025, -0.0189, -0.0030],\n",
      "        [-0.0200,  0.0157, -0.0264,  ..., -0.0177, -0.0215,  0.0225]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "==============\n",
      "\n",
      "Layer: linear_relu_stack.0.bias\n",
      "Size: torch.Size([512])\n",
      "Values:\n",
      "tensor([-0.0073,  0.0322], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "==============\n",
      "\n",
      "Layer: linear_relu_stack.2.weight\n",
      "Size: torch.Size([512, 512])\n",
      "Values:\n",
      "tensor([[ 6.2257e-05, -1.7939e-02, -1.0175e-02,  ...,  2.7330e-02,\n",
      "         -4.1035e-02, -3.8821e-02],\n",
      "        [-1.7885e-02, -3.7783e-02,  3.2482e-02,  ...,  3.6938e-03,\n",
      "         -3.0572e-02, -2.3671e-02]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "==============\n",
      "\n",
      "Layer: linear_relu_stack.2.bias\n",
      "Size: torch.Size([512])\n",
      "Values:\n",
      "tensor([ 0.0150, -0.0423], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "==============\n",
      "\n",
      "Layer: linear_relu_stack.4.weight\n",
      "Size: torch.Size([10, 512])\n",
      "Values:\n",
      "tensor([[ 0.0160, -0.0320,  0.0066,  ..., -0.0060,  0.0377, -0.0160],\n",
      "        [ 0.0438, -0.0061,  0.0163,  ...,  0.0112, -0.0183,  0.0352]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "==============\n",
      "\n",
      "Layer: linear_relu_stack.4.bias\n",
      "Size: torch.Size([10])\n",
      "Values:\n",
      "tensor([ 0.0305, -0.0109], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "interpreter": {
   "hash": "21c7340f8fe3e82379cb27591aa91f7ebf76913d87f67373c88daae97f1a1216"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}